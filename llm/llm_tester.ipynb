{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import info_retriever as ir\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import cohere\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import json\n",
    "import yfinance as yf\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import hnswlib\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "co = cohere.Client(COHERE_API_KEY,\n",
    "                   log_warning_experimental_features=False)\n",
    "\n",
    "perclient = openai.OpenAI(api_key=PERPLEXITY_API_KEY, base_url=\"https://api.perplexity.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_ticker_and_range(prompt):\n",
    "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    ticker = co.chat(\n",
    "        model=\"command-r-plus\",\n",
    "        preamble=\"you are going to return only the ticker for the company that the user is asking about. The ticker should be formatted with MAX 4 characters and MIN 2 characters\",\n",
    "        message=prompt,\n",
    "        connectors=[{\"id\": \"web-search\"}]\n",
    "    )\n",
    "    \n",
    "    pprint(ticker.text)\n",
    "    \n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    preamble=f\"I want you to generate a JSON that represents a query that the user made about a company's stock with ticker, formatted with MAX 4 characters and MIN 2 characters, and the start and end date of the query formatted as YYYY-MM-DD. Today is going to be the date {today} if there is no end date known, do the last year.\",\n",
    "    message=f\"{prompt} this information will help you get the ticker: {ticker.text}\", \n",
    "    response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"required\": [\"tickers\", \"start-date\", \"end-date\"],\n",
    "                \"properties\": {\n",
    "                    \"tickers\": { \"type\": \"array\" },\n",
    "                    \"start-date\": { \"type\": \"string\"},\n",
    "                    \"end-date\": { \"type\": \"string\" }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    # connectors= [{\"id\": \"web-search\"}]\n",
    "    )\n",
    "    \n",
    "    response = json.loads(response.text)\n",
    "    \n",
    "    return response[\"tickers\"], response[\"start-date\"], response[\"end-date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(prompt):\n",
    "    \n",
    "    ticker, start_date, end_date = get_stock_ticker_and_range(prompt)\n",
    "    loaded_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    def __init__(self, raw_documents: List[Dict[str, str]]):\n",
    "        self.raw_documents = raw_documents\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 15\n",
    "        self.rerank_top_k = 5\n",
    "        self.load_and_chunk()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load_and_chunk(self) -> None:\n",
    "        print(\"Loading documents...\")\n",
    "        \n",
    "        def process_document(raw_document):\n",
    "            if \"url\" in raw_document:\n",
    "                return self.process_url_document(raw_document)\n",
    "            else:\n",
    "                return self.process_text_document(raw_document)\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            future_to_doc = {executor.submit(process_document, doc): doc for doc in self.raw_documents}\n",
    "            \n",
    "            for future in tqdm(as_completed(future_to_doc), total=len(self.raw_documents), desc=\"Processing documents\"):\n",
    "                self.docs.extend(future.result())\n",
    "\n",
    "    def process_url_document(self, raw_document):\n",
    "        try:\n",
    "            elements = partition_html(url=raw_document[\"url\"], headers={\"User-Agent\": ir.IDENTITY})\n",
    "            chunks = chunk_by_title(elements)\n",
    "            return [\n",
    "                {\n",
    "                    \"title\": raw_document[\"title\"],\n",
    "                    \"text\": str(chunk),\n",
    "                    \"url\": raw_document[\"url\"],\n",
    "                }\n",
    "                for chunk in chunks\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading URL document: {e}\")\n",
    "            return []\n",
    "\n",
    "    def process_text_document(self, raw_document):\n",
    "        try:\n",
    "            chunks = self.chunk_text(raw_document[\"text\"])\n",
    "            return [\n",
    "                {\n",
    "                    \"title\": raw_document[\"title\"],\n",
    "                    \"text\": chunk,\n",
    "                }\n",
    "                for chunk in chunks\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text document: {e}\")\n",
    "            return []\n",
    "\n",
    "    def chunk_text(self, text, max_chunk_size=1000):\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_size = 0\n",
    "\n",
    "        for word in words:\n",
    "            if current_size + len(word) > max_chunk_size and current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_size = 0\n",
    "            current_chunk.append(word)\n",
    "            current_size += len(word) + 1  # +1 for space\n",
    "\n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            if i % 90 == 0:\n",
    "                print(f\"Processing document chunk {i} of {self.docs_len}...\")\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        print(\"Indexing document chunks...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} document chunks.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "        \n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        rank_fields = [\"title\", \"text\"]\n",
    "\n",
    "        docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v3.0\",\n",
    "            rank_fields=rank_fields\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
    "\n",
    "        docs_retrieved = []\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            retrieved_doc = {\n",
    "                \"title\": self.docs[doc_id][\"title\"],\n",
    "                \"text\": self.docs[doc_id][\"text\"],\n",
    "            }\n",
    "            if \"url\" in self.docs[doc_id]:\n",
    "                retrieved_doc[\"url\"] = self.docs[doc_id][\"url\"]\n",
    "            docs_retrieved.append(retrieved_doc)\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting filings for \n",
      "Getting filings for TSLA between 2023-09-30 00:44:25.095990 and 2024-09-29 00:44:25.095990\n",
      "Getting Benzinga news for \n",
      "Getting Yahoo news for \n"
     ]
    }
   ],
   "source": [
    "raw_documents = []\n",
    "\n",
    "print(\"Getting filings for \")\n",
    "raw_documents += ir.get_all_filings(\"TSLA\")\n",
    "print(\"Getting Benzinga news for \")\n",
    "raw_documents += ir.get_benzinga_news(\"TSLA\")\n",
    "print(\"Getting Yahoo news for \")\n",
    "raw_documents += ir.get_yahoo_news(\"TSLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 57/57 [00:03<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding document chunks...\n",
      "Processing document chunk 0 of 1196...\n",
      "Processing document chunk 90 of 1196...\n",
      "Processing document chunk 180 of 1196...\n",
      "Processing document chunk 270 of 1196...\n",
      "Processing document chunk 360 of 1196...\n",
      "Processing document chunk 450 of 1196...\n",
      "Processing document chunk 540 of 1196...\n",
      "Processing document chunk 630 of 1196...\n",
      "Processing document chunk 720 of 1196...\n",
      "Processing document chunk 810 of 1196...\n",
      "Processing document chunk 900 of 1196...\n",
      "Processing document chunk 990 of 1196...\n",
      "Processing document chunk 1080 of 1196...\n",
      "Processing document chunk 1170 of 1196...\n",
      "Indexing document chunks...\n",
      "Indexing complete with 1196 document chunks.\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Vectorstore(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot(message, chat_history=[]):\n",
    "    print(\"Using perplexity to generate response...\")\n",
    "    \n",
    "    preamble=\"I want you to generate a response to the user's message. you can only use the information that the user has given you in the message. you can't use any external information. you must generate a response that is relevant to the user's message. you cannot generate a response that is irrelevant to the user's message. But you MUST add a citations section at the end, always labeled as CITATIONS, and you MUST add a CITED DOCUMENTS section at the end, always labeled as CITED DOCUMENTS.\",\n",
    "    \n",
    "    # Generate search queries, if any        \n",
    "    response = co.chat(message=message,\n",
    "                        model=\"command-r-plus\",\n",
    "                        search_queries_only=True,\n",
    "                        chat_history=chat_history)\n",
    "    \n",
    "    search_queries = []\n",
    "    for query in response.search_queries:\n",
    "        search_queries.append(query.text)\n",
    "    \n",
    "    # messages = [\n",
    "    #     {\n",
    "    #         \"role\": \"system\",\n",
    "    #         \"content\": preamble\n",
    "    #         },\n",
    "    #     {\n",
    "    #         \"role\": \"user\",\n",
    "    #         \"content\": message\n",
    "    #     }\n",
    "    # ]\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            f\"You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user. {preamble}\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            str(message)\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "    # If there are search queries, retrieve the documents\n",
    "    if search_queries:\n",
    "        print(\"Retrieving information...\", end=\"\")\n",
    "\n",
    "        # Retrieve document chunks for each query\n",
    "        documents = []\n",
    "        for query in search_queries:\n",
    "            documents.extend(vectorstore.retrieve(query))\n",
    "        print(documents)\n",
    "\n",
    "        # Use document chunks to respond\n",
    "        # response = co.chat_stream(\n",
    "        #     preamble=\"I want you to generate a response to the user's message. you can only use the information that the user has given you in the message. you can't use any external information. you must generate a response that is relevant to the user's message. you cannot generate a response that is irrelevant to the user's message.\",\n",
    "        #     message=message,\n",
    "        #     model=\"command-r-plus\",\n",
    "        #     documents=documents,\n",
    "        #     chat_history=chat_history,\n",
    "        # )\n",
    "        \n",
    "        messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            f\"You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user. {preamble}\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"{message} you may use the following information to generate a response but you should generate and use your own sources: {documents}\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "        \n",
    "        response = perclient.chat.completions.create(\n",
    "            model=\"llama-3.1-sonar-large-128k-online\",\n",
    "            messages=messages\n",
    "        )\n",
    "        pprint(response.choices[0].message)\n",
    "\n",
    "    else:\n",
    "        response = perclient.chat.completions.create(\n",
    "            model=\"llama-3.1-sonar-large-128k-online\",\n",
    "            messages=messages\n",
    "        )\n",
    "        pprint(response.choices[0].message)\n",
    "        \n",
    "    # # Print the chatbot response and citations\n",
    "    # chatbot_response = \"\"\n",
    "    # print(\"\\nChatbot:\")\n",
    "\n",
    "    # for event in response:\n",
    "    #     if event.event_type == \"text-generation\":\n",
    "    #         print(event.text, end=\"\")\n",
    "    #         chatbot_response += event.text\n",
    "    #     if event.event_type == \"stream-end\":\n",
    "    #         if event.response.citations:\n",
    "    #             print(\"\\n\\nCITATIONS:\")\n",
    "    #             for citation in event.response.citations:\n",
    "    #                 print(citation)\n",
    "    #         if event.response.documents:\n",
    "    #             print(\"\\nCITED DOCUMENTS:\")\n",
    "    #             for document in event.response.documents:\n",
    "    #                 print(document)\n",
    "    #         # Update the chat history for the next turn\n",
    "    #         chat_history = event.response.chat_history\n",
    "\n",
    "    # return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using perplexity to generate response...\n",
      "Retrieving information...[{'title': \"Tesla, Inc.'s (NASDAQ:TSLA) Stock Is Going Strong: Is the Market Following Fundamentals?\", 'text': \"In this article:\\n\\nTesla's (NASDAQ:TSLA) stock is up by a considerable 32% over the past three months. Since the market usually pay for a company’s long-term fundamentals, we decided to study the company’s key performance indicators to see if they could be influencing the market. Particularly, we will be paying attention to Tesla's ROE today.\", 'url': 'https://finance.yahoo.com/news/tesla-inc-nasdaq-tsla-stock-110032718.html'}, {'title': 'What Happened With Tesla Stock Today?', 'text': \"Tesla operates in the Consumer Discretionary sector. The stock has experienced an average annual growth of -1.06% compared to the -37.76% average of its peer companies. This is below the broader sector movement of Tesla.\\n\\nTSLA Price Action: According to Benzinga Pro, Tesla shares ended Monday's session 1.22% higher at $250.\\n\\nRead Also:\\n\\nShipping Giants FedEx, UPS Stocks Slip Friday: What’s Going On?\", 'url': 'https://www.benzinga.com/news/24/09/40992274/what-happened-with-tesla-stock-today'}, {'title': 'What Happened With Tesla Stock Today?', 'text': 'TSLA Stock Prediction 2024\\n\\nTesla’s revenue growth in FY23 was 18.8%, reflecting the influence of various factors including the macroeconomic environment, demand for its products and services, and its position relative to competitors. This growth is a critical indicator for investors assessing the company’s future prospects.', 'url': 'https://www.benzinga.com/news/24/09/40992274/what-happened-with-tesla-stock-today'}, {'title': 'Tesla Returns To Paris Motor Show For First Time In 6 Years: Cybertruck To Be Featured, Will Elon Musk Present?', 'text': \"The appearance of the Cybertruck and Optimus could be highlights as Tesla makes infrequent appearances at auto shows.\\n\\nIn September, Tesla attended the Detroit Auto Show for the first time in eight years. Similar to the Paris Motor Show, Tesla's last appearance at that auto show came before several of its key vehicles were released.\\n\\nTSLA Price Action: Tesla stock is down 1% to $254.27 on Tuesday versus a 52-week trading range of $138.80 to $271.00. Tesla stock is up 2% year-to-date in 2024.\", 'url': 'https://www.benzinga.com/news/24/09/41027049/tesla-returns-to-paris-motor-show-for-first-time-in-6-years-cybertruck-to-be-featured-will-elon-musk'}, {'title': \"Tesla 'Mojo Is Back,' Tech Analyst Dan Ives Says Ahead Of Q3 Deliveries\", 'text': '\"Overall, we see positive catalysts ahead for Tesla and a compelling risk/reward stock with ‘We, Robot’ robotaxi event coming ahead and solid delivery momentum seen this quarter,\" Ives wrote.\\n\\nThe research firm anticipates Tesla\\'s deliveries to hit 1.8 million in fiscal year 2024. Wedbush maintained its Outperform rating and $300 price target on Tesla stock.\\n\\nTSLA Price Action: According to Benzinga Pro, Tesla shares are up 1.54% at $258.09 at the time of publication Friday.', 'url': 'https://www.benzinga.com/analyst-ratings/analyst-color/24/09/41071876/mojo-is-back-at-tesla-says-tech-analyst-dan-ives-ahead-of-q3-deliveries'}]\n",
      "ChatCompletionMessage(content='To understand the performance of Tesla\\'s stock (TSLA) over the last year, here are some key points:\\n\\n## Price Movement and Year-to-Date Performance\\nAs of 2024, Tesla\\'s stock has experienced significant volatility. After a 102% gain in 2023, the stock price has fallen by 30.4% in 2024, as of April 2024. This decline follows a period of high growth, with the stock trading around $174 per share, which is roughly two-thirds of its previous peak of around $258 in December 2023.\\n\\n## Recent Trends\\nIn the first quarter of 2024, Tesla reported an 8.5% year-over-year decline in vehicle deliveries, which contributed to the stock\\'s decline. However, analysts anticipate potential rebounds in sales due to recent price cuts, the refreshed Model 3, and improved production at the Austin and Berlin factories.\\n\\n## Analyst Predictions\\nFor the remainder of 2024, various analysts have differing forecasts:\\n- Some predict the stock could rise to around $256 by the end of 2024, representing a 16% increase from current levels.\\n- Others forecast a range between $168 and $187 for 2024, with a potential correction and then a gradual rise.\\n- Long-term forecasts suggest the stock could reach $350 by the end of 2024 and continue to rise in subsequent years, driven by growing EV demand and innovations.\\n\\n## Financial Performance\\nTesla\\'s financial performance has been mixed. The company missed earnings and revenue projections in early 2024, with earnings per share expected to be $2.55, down from $4.30 in 2023. However, revenue is expected to rise to $98.2 billion in 2024. The company has maintained positive cash flow and profit since 2020, which supports its financial health.\\n\\n## Market Sentiment\\nDespite the current decline, many analysts remain bullish on Tesla\\'s long-term prospects. The company\\'s strong financial position, with significant cash reserves and minimal debt, supports its ability to fund growth plans and return cash to shareholders. However, competition from traditional automakers and new entrants, particularly from China, poses risks to Tesla\\'s market share and profit margins.\\n\\nIn summary, Tesla\\'s stock has faced challenges in 2024, driven by declining deliveries and increased competition, but analysts see potential for recovery and long-term growth driven by the company\\'s innovative strategies and expanding market demand.\\n\\n## CITATIONS https://www.litefinance.org/blog/analysts-opinions/tesla-stock-price-prediction/ https://coinpriceforecast.com/tesla https://www.morningstar.com/stocks/tesla-stock-is-down-30-2024-is-it-buy https://www.usatoday.com/money/blueprint/investing/stock-forecast-tesla/\\n\\n## CITED DOCUMENTS\\n- LiteFinance: \"Tesla (TSLA) Stock Forecast for 2024, 2025, 2026–2030 and Beyond\"\\n- Coin Price Forecast: \"TESLA STOCK FORECAST 2024 - 2025 - 2030\"\\n- Morningstar: \"Tesla Stock Is Down 30% In 2024. Is It a Buy?\"\\n- USA Today: \"Tesla (TSLA) Stock Forecast and Price Prediction\"', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "run_chatbot(\"tell me about the performance of the TSLA stock over the last year\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
